{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量tensor的概念\n",
    "Tensor 是深度学习框架中极为基础的概念，也是 PyTroch、TensorFlow 中最重要的知识点之一，它是一种数据的存储和处理结构。\n",
    "#### 几个概念\n",
    "* 标量，也称 Scalar，是一个只有大小，没有方向的量，比如 1.8、e、10 等\n",
    "* 向量，也称 Vector，是一个有大小也有方向的量，比如 (1,2,3,4) 等。\n",
    "* 矩阵，也称 Matrix，是多个向量合并在一起得到的量，比如[(1,2,3),(4,5,6)]等。\n",
    "* 张量 (Tensor) 可以统一标量、向量、矩阵的概念\n",
    "* Tensor 的概念中，使用 Rank（秩）来表示这种“维度”，标量，就是 Rank 为 0 阶的 Tensor；向量就是 Rank 为 1 阶的 Tensor；矩阵就是 Rank 为 2 阶的 Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建张量基本用法\n",
    "`torch.tensor(data, dtype=None, device=None,requires_grad=False)`\n",
    "* data，要传入模型的数据\n",
    "* dtype，它声明了你需要返回一个怎样类型的 Tensor，具体类型可以参考前面表格里列举的 Tensor 的 8 种类型。\n",
    "* requires_grad，用于说明当前量是否需要在计算中保留对应的梯度信息。\n",
    "* device，这个参数指定了数据要返回到的设备\n",
    "* requires_grad，用于说明当前量是否需要在计算中保留对应的梯度信息。只有当一个 Tensor 设置 requires_grad 为 True 的情况下，才会对这个 Tensor 以及由这个 Tensor 计算出来的其他 Tensor 进行求导，然后将导数值存在 Tensor 的 grad 属性中，便于优化器来更新参数。\n",
    "* 把 requires_grad 设置成 true 或者 false 要灵活处理。如果是训练过程就要设置为 true，目的是方便求导、更新参数。而到了验证或者测试过程，我们的目的是检查当前模型的泛化能力，那就要把 requires_grad 设置成 Fasle，避免这个参数根据 loss 自动更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([[0.4032, 0.7474, 0.3448, 0.4291],\n",
      "        [0.3893, 0.3258, 0.1644, 0.2924]])\n",
      "tensor([4, 2, 7, 9, 3, 5, 0, 6, 1, 8])\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# 使用 torch\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(x)\n",
    "a = torch.rand(2,4)\n",
    "print(a)\n",
    "b = torch.randperm(10)\n",
    "print(b)\n",
    "print(b.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 从numpy中转换数据\n",
    "ndarry = np.array([1,2,3])\n",
    "tensor_array = torch.from_numpy(ndarry)\n",
    "print(tensor_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 几种常见创建张量的用法\n",
    "* 创建零矩阵 Tensor `torch.zeros(*size, dtype=None...)`\n",
    "* 创建单位矩阵 Tensor：单位矩阵是指主对角线上的元素都为 1 的矩阵 `torch.eye(size, dtype=None...)`\n",
    "* 创建全一矩阵 Tensor：全一矩阵顾名思义，就是所有的元素都为 1 的矩阵 `torch.ones(size, dtype=None...)`\n",
    "* `torch.rand` 用于生成数据类型为浮点型且维度指定的随机 Tensor，随机生成的浮点数据在 0~1 区间均匀分布。\n",
    "* `torch.randn` 用于生成数据类型为浮点型且维度指定的随机 Tensor，随机生成的浮点数的取值满足均值为 0、方差为 1 的标准正态分布。\n",
    "* `torch.normal` 用于生成数据类型为浮点型且维度指定的随机 Tensor，可以指定均值和标准差。\n",
    "* `torch.randint` 用于生成随机整数的 Tensor，其内部填充的是在[low,high) 均匀生成的随机整数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常见创建张量用法\n",
    "torch.rand(size)\n",
    "torch.randn(size)\n",
    "torch.normal(mean, std, size)\n",
    "torch.randint(low, high, size）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 张量、标量、向量、矩阵的转换\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#标量转换\n",
    "a = torch.tensor(1)\n",
    "b = a.item()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3] tensor([1, 2, 3]) [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# 向量转换\n",
    "a = [1, 2, 3]\n",
    "b = torch.tensor(a)\n",
    "c = b.numpy().tolist()\n",
    "print(a, b, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 从numpy中转换数据\n",
    "ndarry = np.array([1,2,3])\n",
    "na = torch.tensor(ndarry)\n",
    "print(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cpu与gpu切换\n",
    "na.cuda()\n",
    "# na.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "torch.Size([2, 3, 5])\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# 创建一个三维0向量\n",
    "a=torch.zeros(2, 3, 5)\n",
    "# 张量的维度信息，属性获取\n",
    "print(a.shape)\n",
    "# 张量的维度信息，方法获取\n",
    "print(a.size())\n",
    "# 张量元素个数\n",
    "count = a.numel()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "torch.Size([5, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# 矩阵转秩 维度转换\n",
    "x = torch.randn(2,3,5)\n",
    "print(x.shape)\n",
    "#矩阵按照原始矩阵的2,1,0三个通道顺序进行转秩,可以一次性对多个维度进行转化\n",
    "x = x.permute(2,1,0)\n",
    "print(x.shape)\n",
    "# 将矩阵\n",
    "x = x.transpose(2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "tensor([[-0.8668, -1.4835,  0.8716, -0.3166],\n",
      "        [-1.2438, -0.5077, -0.7945, -0.9906],\n",
      "        [-1.0614, -2.3561,  0.0124,  0.6183],\n",
      "        [-1.4219, -2.8857, -1.8384,  0.1188]])\n",
      "torch.Size([2, 8])\n",
      "tensor([[-0.8668, -1.4835,  0.8716, -0.3166, -1.2438, -0.5077, -0.7945, -0.9906],\n",
      "        [-1.0614, -2.3561,  0.0124,  0.6183, -1.4219, -2.8857, -1.8384,  0.1188]])\n",
      "torch.Size([8, 2])\n",
      "tensor([[-0.8668, -1.0614],\n",
      "        [-1.4835, -2.3561],\n",
      "        [ 0.8716,  0.0124],\n",
      "        [-0.3166,  0.6183],\n",
      "        [-1.2438, -1.4219],\n",
      "        [-0.5077, -2.8857],\n",
      "        [-0.7945, -1.8384],\n",
      "        [-0.9906,  0.1188]])\n",
      "torch.Size([4, 4])\n",
      "tensor([[-0.8668, -1.0614, -1.4835, -2.3561],\n",
      "        [ 0.8716,  0.0124, -0.3166,  0.6183],\n",
      "        [-1.2438, -1.4219, -0.5077, -2.8857],\n",
      "        [-0.7945, -1.8384, -0.9906,  0.1188]])\n"
     ]
    }
   ],
   "source": [
    "# 形状改变\n",
    "x = torch.randn(4, 4)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "# 通过view函数进行形变\n",
    "x = x.view(2,8)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "# 进行维度变换\n",
    "x = x.permute(1,0)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "# view无法处理内存不连续的数据\n",
    "#x = x.view(4,4)\n",
    "x = x.reshape(4,4)\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### squeeze and unsqueeze\n",
    "* squeeze 压缩维度,如果指定压缩维度为1，则允许压缩\n",
    "* unsqueeze 扩大维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3])\n",
      "tensor([[[0.7666, 0.9499, 0.8547]],\n",
      "\n",
      "        [[0.4880, 0.0754, 0.4169]]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0.7666, 0.9499, 0.8547],\n",
      "        [0.4880, 0.0754, 0.4169]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0.7666, 0.9499, 0.8547],\n",
      "        [0.4880, 0.0754, 0.4169]])\n"
     ]
    }
   ],
   "source": [
    "# 对张量进行维度增减\n",
    "x = torch.rand(2,1, 3)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "# 将维度为1的维度删除,1的维度大小为1，所以可以删除\n",
    "x = x.squeeze(1)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "# 维度大小不为1，为3，不允许删除\n",
    "x = x.squeeze(1)\n",
    "print(x.shape)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3])\n",
      "tensor([[[0.5976, 0.7018, 0.9851]],\n",
      "\n",
      "        [[0.8096, 0.2992, 0.5045]]])\n",
      "torch.Size([2, 1, 1, 3])\n",
      "tensor([[[[0.5976, 0.7018, 0.9851]]],\n",
      "\n",
      "\n",
      "        [[[0.8096, 0.2992, 0.5045]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,1,3)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "# 在第二维度插入一个维度\n",
    "y = x.unsqueeze(2)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor的连接操作\n",
    "* cat : 连接两个tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.ones(3,3)\n",
    "B = torch.ones(3,3) * 2\n",
    "print(A)\n",
    "print(B)\n",
    "# 二维场景中按行进行拼接\n",
    "C = torch.cat((A,B), dim=0)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 2., 2., 2.],\n",
      "        [1., 1., 1., 2., 2., 2.],\n",
      "        [1., 1., 1., 2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# 二维场景中按列进行拼接\n",
    "D=torch.cat((A,B),1)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor中的维度扩展连接操作，将2个tensor按维度连接扩展维度\n",
    "* stack函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n",
      "tensor([5, 6, 7, 8])\n",
      "torch.Size([2, 4])\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [5, 6, 7, 8]])\n",
      "torch.Size([4, 2])\n",
      "tensor([[0, 5],\n",
      "        [1, 6],\n",
      "        [2, 7],\n",
      "        [3, 8]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个标量，从0到4\n",
    "A=torch.arange(0,4)\n",
    "print(A)\n",
    "B=torch.arange(5,9)\n",
    "print(B)\n",
    "# 进行维度拓展\n",
    "C = torch.stack((A,B),0)\n",
    "print(C.shape)\n",
    "print(C)\n",
    "D = torch.stack((A,B),1)\n",
    "print(D.shape)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.],\n",
      "         [2., 2., 2.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [2., 2., 2.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [2., 2., 2.]]])\n",
      "torch.Size([3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "## 二维转三维\n",
    "A = torch.zeros(3,3)\n",
    "B = torch.ones(3,3) * 2\n",
    "C = torch.stack((A,B),dim=1)\n",
    "print(C)\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensor切分操作\n",
    "* chunk 的作用就是将 Tensor 按照声明的 dim，进行尽可能平均的划分。\n",
    "`torch.chunk(input, chunks, dim=0)`\n",
    "input ：操作得目标张量\n",
    "chunks ：切分份数，当无法均匀切分时，chunk 函数是先做除法，然后再向上取整得到每组的数量。\n",
    "dim ：按那个维度进行切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1, 2, 3, 4]), tensor([5, 6, 7, 8]), tensor([ 9, 10]))\n"
     ]
    }
   ],
   "source": [
    "A=torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "B = torch.chunk(A,3,0)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "(tensor([1]), tensor([2]), tensor([3]))\n"
     ]
    }
   ],
   "source": [
    "# 只能进行整数切分，切分成三个大小为1的向量\n",
    "A=torch.tensor([1,2,3])\n",
    "print(A)\n",
    "B = torch.chunk(A,5,0)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "(tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]), tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]))\n",
      "(tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]]), tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]]))\n"
     ]
    }
   ],
   "source": [
    "A=torch.ones(4,4)\n",
    "print(A)\n",
    "## 二维切分,按行切分\n",
    "B= torch.chunk(A,2,dim=0)\n",
    "print(B)\n",
    "C = torch.chunk(A,2,dim=1)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "(tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]]), tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]]))\n"
     ]
    }
   ],
   "source": [
    "A  = torch.ones(4,4,4)\n",
    "print(A)\n",
    "# 三维切分，按0轴切分，得到两个tensor\n",
    "B = torch.chunk(A,2,dim=0)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split 每份按照确定的大小来进行切分\n",
    "`torch.split(tensor, split_size_or_sections, dim=0)`\n",
    "* split_size_or_sections : 按每组split_size_or_sections来进行切分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6285, 0.3949, 0.1863, 0.6175],\n",
      "        [0.3153, 0.2345, 0.4112, 0.3810],\n",
      "        [0.6760, 0.8108, 0.0604, 0.1892],\n",
      "        [0.4647, 0.3733, 0.4734, 0.0106]])\n",
      "(tensor([[0.6285, 0.3949, 0.1863, 0.6175],\n",
      "        [0.3153, 0.2345, 0.4112, 0.3810],\n",
      "        [0.6760, 0.8108, 0.0604, 0.1892]]), tensor([[0.4647, 0.3733, 0.4734, 0.0106]]))\n"
     ]
    }
   ],
   "source": [
    "A=torch.rand(4,4)\n",
    "print(A)\n",
    "# 按每组3份来切分\n",
    "B=torch.split(A, 3, 0)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0648, 0.1987, 0.0448, 0.0696, 0.1688, 0.9365],\n",
      "        [0.0477, 0.0377, 0.9269, 0.3760, 0.1937, 0.2363],\n",
      "        [0.1054, 0.7226, 0.1067, 0.3941, 0.1434, 0.8138],\n",
      "        [0.4498, 0.4290, 0.0954, 0.3464, 0.8172, 0.9115],\n",
      "        [0.8246, 0.9588, 0.6681, 0.6360, 0.0501, 0.1199]])\n",
      "(tensor([[0.0648, 0.1987, 0.0448, 0.0696, 0.1688, 0.9365],\n",
      "        [0.0477, 0.0377, 0.9269, 0.3760, 0.1937, 0.2363]]), tensor([[0.1054, 0.7226, 0.1067, 0.3941, 0.1434, 0.8138],\n",
      "        [0.4498, 0.4290, 0.0954, 0.3464, 0.8172, 0.9115],\n",
      "        [0.8246, 0.9588, 0.6681, 0.6360, 0.0501, 0.1199]]))\n"
     ]
    }
   ],
   "source": [
    "A=torch.rand(5,6)\n",
    "print(A)\n",
    "# 按2行，3行的规格沿着0轴进行切分\n",
    "B= torch.split(A,(2,3),0)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 降维切分 unbind,将一个维度删除\n",
    "torch.unbind(input, dim=0)\n",
    "将某一个维度进行切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "(tensor([0, 1, 2, 3]), tensor([4, 5, 6, 7]), tensor([ 8,  9, 10, 11]), tensor([12, 13, 14, 15]))\n"
     ]
    }
   ],
   "source": [
    "A=torch.arange(0,16).view(4,4)\n",
    "print(A)\n",
    "# 按0轴进行降维切分\n",
    "B = torch.unbind(A,dim=0)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor索引操作 对张量的一部分进行操作\n",
    "* index_select(input, dim, index) 基于给定的索引来进行数据提取， index是torch.Tensor类型\n",
    "* torch.masked_select(input, mask, out=None) 通过一些判断条件来进行选择 ，mask掩码张量,input 中“满足 mask 里面元素值为 True 的”对应位置的数据\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "tensor([[ 4,  5,  6,  7],\n",
      "        [12, 13, 14, 15]])\n",
      "tensor([[ 0,  3],\n",
      "        [ 4,  7],\n",
      "        [ 8, 11],\n",
      "        [12, 15]])\n"
     ]
    }
   ],
   "source": [
    "A=torch.arange(0,16).view(4,4)\n",
    "print(A)\n",
    "# 从第 0 维选择第 1（行）和 3（行）的数据\n",
    "B= torch.index_select(A,0,torch.tensor([1,3]))\n",
    "print(B)\n",
    "# 从第 1 维选择第 0（列）和 3（列）的数据\n",
    "C = torch.index_select(A,1,torch.tensor([0,3]))\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3858, 0.7913, 0.1739, 0.9991, 0.3034])\n",
      "tensor([ True,  True, False,  True,  True])\n",
      "tensor([0.3858, 0.7913, 0.9991, 0.3034])\n",
      "tensor([0.3858, 0.7913, 0.9991, 0.3034])\n"
     ]
    }
   ],
   "source": [
    "# masked_select 举例\n",
    "A=torch.rand(5)\n",
    "print(A)\n",
    "mask = A > 0.3\n",
    "print(mask)\n",
    "# 从A中取出mask位置为true的元素\n",
    "C = torch.masked_select(A, mask)\n",
    "print(C)\n",
    "#简化写法\n",
    "C = torch.masked_select(A, A>0.3)\n",
    "print(C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 5, 7],\n",
      "        [3, 9, 8],\n",
      "        [2, 3, 4]])\n",
      "tensor([[1, 0, 0],\n",
      "        [1, 1, 0],\n",
      "        [0, 0, 1]])\n",
      "tensor([[4, 0, 0],\n",
      "        [3, 9, 0],\n",
      "        [0, 0, 4]])\n",
      "tensor([4, 3, 9, 4])\n",
      "tensor([4, 3, 9, 4])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4, 9, 4])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实际举例：提取出其中第一行的第一个，第二行的第一、第二个，第三行的最后一个\n",
    "A=torch.tensor([[4,5,7], [3,9,8],[2,3,4]])\n",
    "print(A)\n",
    "B=torch.tensor([[1,0,0],[1,1,0],[0,0,1]])\n",
    "print(B)\n",
    "# A * B 每个元素对应位置相乘\n",
    "print(A * B)\n",
    "C=torch.masked_select(A, A*B!=0)\n",
    "print(C)\n",
    "\n",
    "mask = torch.tensor([[1, 0, 0], [1, 1, 0], [0, 0, 1]])\n",
    "D = torch.masked_select(A, mask>0)\n",
    "print(D)\n",
    "\n",
    "eye  = torch.eye(3)\n",
    "print(eye)\n",
    "torch.masked_select(A,eye>0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个需要求导的矩阵\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3435,  0.1521,  1.6209, -1.3845],\n",
      "        [ 0.7553,  0.4105, -0.9160,  0.2289],\n",
      "        [ 0.6783,  0.5005, -1.4680,  2.5069]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,4,requires_grad=True)\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(python-learning)",
   "language": "python",
   "name": "python-learning"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
