{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 识别手写数字算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 60000\n",
      "Testing set size: 10000\n",
      "Batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 定义数据变换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图像转换为 Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 归一化到 [-1, 1]\n",
    "])\n",
    "\n",
    "# 下载和加载训练集\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "# 下载和加载测试集\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# 检查数据集\n",
    "print(\"Training set size:\", len(trainset))\n",
    "print(\"Testing set size:\", len(testset))\n",
    "\n",
    "# 检查 DataLoader\n",
    "for images, labels in trainloader:\n",
    "    print(\"Batch shape:\", images.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "    break  # 只检查第一个批次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "12.4\n",
      "True\n",
      "NVIDIA GeForce GTX 1660 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/10], Loss: 0.2618\n",
      "Epoch [2/10], Loss: 0.0993\n",
      "Epoch [3/10], Loss: 0.0760\n",
      "Epoch [4/10], Loss: 0.0616\n",
      "Epoch [5/10], Loss: 0.0525\n",
      "Epoch [6/10], Loss: 0.0444\n",
      "Epoch [7/10], Loss: 0.0389\n",
      "Epoch [8/10], Loss: 0.0373\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 定义数据变换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图像转换为 Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 归一化到 [-1, 1]\n",
    "])\n",
    "\n",
    "# 使用gpu设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 下载和加载训练集\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "# 下载和加载测试集\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "# 定义卷积神经网络模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 一次卷积\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        # 第二次卷积\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        # 池化\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # 线性化\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 一次卷积、池化\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        # 第二次卷积、池化\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)  # 展平特征图\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 初始化模型\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        # 将数据移动到设备\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / (i+1):.4f}\")\n",
    "# 评估模型\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # 将数据移动到设备\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1.weight\n",
      "Shape: torch.Size([32, 1, 3, 3])\n",
      "Weights: tensor([[[[ 2.3706e-01,  4.6119e-01, -4.8815e-01],\n",
      "          [ 3.5104e-01,  7.3091e-02, -3.7746e-01],\n",
      "          [ 3.8694e-01, -2.1147e-02, -2.0529e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1271e-01,  4.6229e-01, -1.6504e-01],\n",
      "          [-3.7713e-01, -1.5652e-02, -4.7327e-02],\n",
      "          [-3.8989e-01,  3.0919e-01,  1.6321e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9148e-01,  1.3315e-01, -7.7517e-02],\n",
      "          [ 2.7989e-01, -4.1656e-01, -2.4794e-01],\n",
      "          [-1.3641e-01, -2.5066e-01,  4.2413e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.5018e-01, -4.0249e-02, -1.5749e-02],\n",
      "          [ 1.0359e-01, -2.8127e-01,  1.1100e-01],\n",
      "          [-2.7273e-01,  3.0265e-01,  2.4412e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.2695e-01,  1.0266e-01,  1.2416e-01],\n",
      "          [-4.4353e-02,  1.9406e-01,  1.9548e-01],\n",
      "          [ 3.3752e-01, -9.2409e-02, -1.5962e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1533e-01, -2.7183e-01,  3.0623e-01],\n",
      "          [ 3.1181e-01,  1.8476e-01,  6.5520e-02],\n",
      "          [-3.9635e-02, -2.7701e-01, -8.5967e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5635e-01,  1.3304e-01, -1.0011e-01],\n",
      "          [ 3.0866e-01,  1.2448e-01,  1.6581e-01],\n",
      "          [-8.4933e-02,  1.6298e-02, -3.3867e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7614e-01,  3.3665e-01, -5.3120e-02],\n",
      "          [ 1.7982e-01,  2.2217e-04, -4.8245e-01],\n",
      "          [ 3.5610e-01,  2.8969e-01, -1.7365e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1326e-01, -2.8883e-01,  2.1054e-03],\n",
      "          [ 1.0135e-01,  2.6113e-01,  2.5076e-01],\n",
      "          [ 1.2997e-01,  9.8623e-02, -4.1777e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2050e-01, -1.4101e-02,  3.8985e-01],\n",
      "          [ 3.4753e-01,  1.0836e-01, -1.4148e-01],\n",
      "          [-3.6212e-01, -2.9612e-01, -3.4205e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.9636e-02, -7.0642e-01, -2.6185e-01],\n",
      "          [ 2.3688e-01,  5.2503e-01,  2.1692e-01],\n",
      "          [ 1.2762e-01, -3.8777e-02, -3.8289e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2066e-02, -2.8066e-01,  3.1196e-01],\n",
      "          [-2.5976e-01, -1.3164e-02,  2.3491e-01],\n",
      "          [-9.8227e-02, -3.1826e-01,  4.2662e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6051e-01,  6.3417e-02, -2.5150e-01],\n",
      "          [-2.0149e-01,  6.4442e-01, -1.0119e-01],\n",
      "          [-4.3256e-01,  9.5246e-02,  1.6201e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9514e-01, -2.2425e-01, -1.2437e-01],\n",
      "          [-1.8061e-01, -1.2884e-01, -1.1833e-01],\n",
      "          [-3.1642e-01, -1.5229e-01,  1.4433e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2189e-01, -2.0599e-01, -4.6881e-02],\n",
      "          [-3.0514e-01, -1.6165e-01, -8.0649e-02],\n",
      "          [-2.6077e-01, -1.1660e-01, -3.0748e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2023e-01,  1.2322e-01, -1.3896e-01],\n",
      "          [-1.9335e-01, -5.0037e-02, -1.7482e-01],\n",
      "          [-1.9634e-01, -3.4042e-01, -2.7100e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0851e-01,  3.3076e-01, -2.9387e-01],\n",
      "          [-5.3143e-02,  2.9931e-01, -4.1569e-01],\n",
      "          [-1.2332e-01,  3.4485e-01,  3.8500e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1734e-01,  5.2828e-01,  4.2179e-01],\n",
      "          [-3.9267e-01, -1.4366e-01,  2.5394e-01],\n",
      "          [-3.6251e-01, -4.1085e-01,  1.1738e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6953e-01,  8.2467e-02, -1.8929e-01],\n",
      "          [-4.7336e-01, -3.6090e-01,  5.5112e-02],\n",
      "          [ 4.7118e-01,  5.5520e-01,  9.3821e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.9448e-03,  2.4391e-01,  3.2632e-01],\n",
      "          [ 1.0616e-01, -1.9696e-01,  2.8612e-01],\n",
      "          [-9.3387e-02, -3.7600e-01, -1.7900e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.2048e-01, -3.7868e-01,  2.4997e-01],\n",
      "          [-2.4578e-01,  4.6688e-02,  3.4470e-01],\n",
      "          [-2.0438e-01,  4.1219e-01,  2.6285e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5861e-01,  1.0322e-01,  2.9558e-01],\n",
      "          [ 4.6381e-01,  4.8230e-02,  3.2110e-01],\n",
      "          [ 2.2357e-01,  2.9141e-01, -6.2934e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.5097e-01,  4.0072e-01,  1.5351e-01],\n",
      "          [ 1.5264e-01,  7.5767e-02, -1.0914e-01],\n",
      "          [ 1.2496e-01,  5.1433e-02, -3.0321e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.6037e-02,  8.2004e-02,  3.7704e-01],\n",
      "          [ 2.2788e-02,  3.1138e-01, -1.3761e-01],\n",
      "          [ 1.8744e-02, -3.4837e-01, -2.3471e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4860e-01,  2.1408e-01, -2.4816e-01],\n",
      "          [ 5.2159e-01, -4.8667e-01, -5.0400e-01],\n",
      "          [ 3.4753e-01,  4.8103e-01,  2.6422e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4552e-01, -4.0697e-01,  4.7875e-02],\n",
      "          [-4.7669e-01, -5.2750e-03,  5.1375e-01],\n",
      "          [ 3.8586e-01,  6.2894e-01, -5.5497e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0659e-01,  4.1520e-01,  2.4141e-01],\n",
      "          [-4.5338e-01, -2.2128e-01,  3.5116e-01],\n",
      "          [-1.4212e-01, -2.3083e-01,  3.5600e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7111e-01,  8.0338e-02, -1.0096e-01],\n",
      "          [ 7.6799e-03,  1.8684e-01,  2.5951e-01],\n",
      "          [-6.1750e-02,  7.7641e-02,  3.1783e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4134e-01,  8.1971e-02,  1.1898e-01],\n",
      "          [ 3.6375e-01, -2.0822e-02, -1.8810e-01],\n",
      "          [ 4.0518e-01, -3.2731e-01, -3.1085e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6527e-01,  2.3724e-01,  3.6747e-01],\n",
      "          [-6.2037e-02,  1.1049e-02,  6.0515e-02],\n",
      "          [-3.6066e-01, -3.0173e-01, -3.9063e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1199e-01, -3.7592e-01, -5.3442e-01],\n",
      "          [ 6.7974e-02, -3.4649e-02, -1.0497e-01],\n",
      "          [ 6.7353e-01,  1.4415e-01,  6.8618e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2304e-03,  2.1695e-02, -1.0445e-01],\n",
      "          [ 2.4796e-01,  2.7805e-01,  4.1283e-01],\n",
      "          [-3.4730e-01, -2.2477e-01, -3.1585e-01]]]], device='cuda:0')\n",
      "\n",
      "Layer: conv1.bias\n",
      "Shape: torch.Size([32])\n",
      "Weights: tensor([-0.1229, -0.1189, -0.0103, -0.2074, -0.0168,  0.0047, -0.0487,  0.0481,\n",
      "        -0.0135, -0.0691, -0.0357, -0.1208, -0.0589, -0.4109, -0.1417, -0.2327,\n",
      "        -0.1972, -0.1814, -0.0673,  0.0613, -0.1366, -0.0421, -0.0887,  0.0415,\n",
      "        -0.2067, -0.2157, -0.2138, -0.2175,  0.1005, -0.0965, -0.1036, -0.0615],\n",
      "       device='cuda:0')\n",
      "\n",
      "Layer: conv2.weight\n",
      "Shape: torch.Size([64, 32, 3, 3])\n",
      "Weights: tensor([[[[-3.3667e-03, -8.6883e-03, -8.1992e-03],\n",
      "          [ 2.7214e-02,  1.3864e-02, -3.7750e-02],\n",
      "          [-1.7614e-02,  1.8449e-02,  2.6688e-04]],\n",
      "\n",
      "         [[-2.7416e-02, -4.1822e-03,  1.4668e-02],\n",
      "          [ 2.3174e-02, -4.6233e-02, -1.6824e-02],\n",
      "          [-5.8710e-02, -2.8001e-02, -6.4885e-02]],\n",
      "\n",
      "         [[-3.2804e-02,  5.3349e-03, -2.7832e-02],\n",
      "          [-2.6386e-02,  3.1987e-02,  1.5480e-04],\n",
      "          [-1.3180e-02, -1.1098e-02, -4.4052e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.3344e-02, -4.5803e-02, -3.2212e-02],\n",
      "          [ 2.2799e-02, -4.4484e-02,  3.7470e-02],\n",
      "          [-2.5214e-02, -1.7230e-02,  3.0757e-02]],\n",
      "\n",
      "         [[ 1.3653e-02, -6.3648e-02, -4.5248e-02],\n",
      "          [-1.7824e-02, -2.1819e-02,  3.3480e-02],\n",
      "          [ 8.4981e-06, -8.3512e-04, -3.2179e-02]],\n",
      "\n",
      "         [[ 4.2968e-02,  2.0534e-04,  1.3505e-02],\n",
      "          [ 4.6283e-02,  9.0685e-03, -5.7418e-02],\n",
      "          [-8.5731e-04, -4.0331e-02,  3.7809e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3818e-02, -2.0760e-02, -1.7502e-01],\n",
      "          [-9.7736e-02, -8.9271e-03, -1.3923e-01],\n",
      "          [ 1.7061e-01,  1.3676e-01, -6.3446e-02]],\n",
      "\n",
      "         [[ 9.4684e-02,  1.4259e-01, -2.7499e-01],\n",
      "          [ 9.3592e-02,  4.8854e-02, -5.2067e-02],\n",
      "          [-1.4074e-01, -2.4307e-02,  3.5607e-02]],\n",
      "\n",
      "         [[ 3.9370e-02, -3.5214e-02, -8.9336e-02],\n",
      "          [ 1.9997e-01, -2.1741e-02, -5.4052e-02],\n",
      "          [ 1.3433e-01,  1.4520e-01, -1.0053e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.5328e-02, -3.3281e-01, -5.6861e-01],\n",
      "          [-7.0338e-02, -7.8995e-02, -5.5488e-02],\n",
      "          [-2.0971e-01,  2.9677e-02, -2.4752e-02]],\n",
      "\n",
      "         [[ 1.4200e-01,  1.7504e-01,  6.0115e-02],\n",
      "          [-1.8639e-01,  1.0235e-02,  9.6036e-02],\n",
      "          [-6.1073e-02, -1.3486e-01, -1.1174e-01]],\n",
      "\n",
      "         [[ 1.3315e-01,  2.1945e-02, -2.4865e-01],\n",
      "          [-7.6171e-02, -1.7344e-01, -8.6330e-02],\n",
      "          [ 8.0477e-02,  3.5700e-02, -6.4937e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.4880e-02, -1.6286e-01, -1.6510e-02],\n",
      "          [-1.1824e-01, -1.1224e-01,  1.0127e-01],\n",
      "          [-8.6972e-02, -7.0741e-02,  1.6427e-02]],\n",
      "\n",
      "         [[-2.3566e-01,  4.3882e-03, -3.5089e-02],\n",
      "          [-1.6681e-01, -1.6447e-02,  6.0792e-02],\n",
      "          [ 7.1363e-02, -1.3183e-03, -1.1525e-01]],\n",
      "\n",
      "         [[-1.1731e-01, -8.1002e-02, -8.5872e-02],\n",
      "          [-3.5461e-02, -9.1181e-03, -4.9618e-02],\n",
      "          [ 1.2844e-01, -1.1725e-02, -7.8259e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1934e-01, -1.8734e-01, -2.8756e-01],\n",
      "          [-6.2553e-03, -3.2516e-01, -4.0307e-01],\n",
      "          [-2.2006e-02, -3.4251e-01, -2.4979e-01]],\n",
      "\n",
      "         [[-5.8349e-02, -2.4327e-01, -2.6394e-01],\n",
      "          [ 3.4373e-02, -2.5836e-01, -1.9139e-01],\n",
      "          [-2.7957e-02, -2.2352e-01, -1.5516e-01]],\n",
      "\n",
      "         [[-1.0164e-01, -2.4793e-01, -1.1808e-01],\n",
      "          [ 5.8408e-03, -1.0885e-01, -2.2618e-01],\n",
      "          [-1.4143e-03, -1.9433e-01, -1.6057e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-7.9670e-03,  8.2710e-02, -7.6351e-02],\n",
      "          [-1.0140e-01,  6.7648e-02, -3.1490e-02],\n",
      "          [-1.1793e-01, -9.5235e-02, -2.1245e-02]],\n",
      "\n",
      "         [[-2.4551e-02, -6.8830e-02, -7.0487e-02],\n",
      "          [ 6.6847e-02,  1.0863e-01, -1.3161e-01],\n",
      "          [ 1.5644e-01,  2.3412e-01,  1.4290e-03]],\n",
      "\n",
      "         [[ 2.6590e-02,  1.1166e-01,  6.3547e-02],\n",
      "          [-7.9388e-02, -1.9243e-03,  3.7394e-04],\n",
      "          [ 1.5274e-01, -1.5989e-02,  4.8260e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7032e-01, -4.4991e-02,  1.7629e-02],\n",
      "          [ 1.2266e-01, -7.6291e-03, -1.3845e-01],\n",
      "          [ 5.5907e-02,  4.5321e-02, -9.8952e-02]],\n",
      "\n",
      "         [[ 7.3918e-02,  8.0587e-02, -8.8870e-03],\n",
      "          [-2.7226e-02,  1.9030e-01,  1.2989e-01],\n",
      "          [-2.2209e-01, -6.5900e-02,  7.3485e-02]],\n",
      "\n",
      "         [[-3.8441e-02, -1.5416e-01,  8.5796e-02],\n",
      "          [ 1.0387e-01,  1.2069e-01, -2.3210e-01],\n",
      "          [-2.9575e-02, -2.4925e-02, -1.3835e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9791e-02,  3.8858e-02,  3.7430e-02],\n",
      "          [-3.0636e-01,  8.8768e-02,  6.5847e-02],\n",
      "          [-4.0629e-02, -3.4236e-03,  1.2523e-01]],\n",
      "\n",
      "         [[ 6.2445e-02, -5.5364e-02, -2.2308e-01],\n",
      "          [-7.0884e-02, -5.5688e-02, -2.3270e-01],\n",
      "          [-9.9181e-03,  7.7380e-03, -1.2344e-01]],\n",
      "\n",
      "         [[-2.0219e-02, -1.3018e-01, -6.2829e-02],\n",
      "          [-5.4896e-02, -1.1787e-01,  4.6697e-02],\n",
      "          [-7.0928e-02, -6.2507e-02,  1.1384e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8351e-02, -2.1663e-01,  4.0547e-02],\n",
      "          [-8.8404e-02, -1.8040e-01, -1.2867e-01],\n",
      "          [-2.0818e-01, -1.2447e-01, -1.9458e-02]],\n",
      "\n",
      "         [[-2.0585e-01, -3.8072e-01, -2.0838e-01],\n",
      "          [-4.0664e-01, -1.8832e-01,  1.5527e-02],\n",
      "          [-3.0288e-01, -1.5320e-01,  3.7849e-02]],\n",
      "\n",
      "         [[-1.6594e-01, -2.4373e-01,  3.5579e-02],\n",
      "          [-2.2971e-01, -2.3778e-01, -1.5629e-01],\n",
      "          [-1.7044e-01, -4.0067e-02, -5.0491e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5060e-01,  2.8305e-01,  1.3097e-01],\n",
      "          [ 5.7117e-02,  2.5585e-01, -1.9783e-01],\n",
      "          [-1.9644e-01, -1.7782e-01, -7.3473e-02]],\n",
      "\n",
      "         [[-5.5049e-03,  5.4936e-02, -1.1001e-01],\n",
      "          [-1.1722e-01,  6.9254e-02, -2.7562e-01],\n",
      "          [-1.5347e-01, -1.0683e-01, -1.9806e-01]],\n",
      "\n",
      "         [[-1.8420e-01,  1.6849e-01,  1.0161e-01],\n",
      "          [-1.6248e-01,  1.8590e-01,  5.1772e-02],\n",
      "          [-1.2578e-01, -1.2688e-02, -1.0494e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.6334e-02, -6.4152e-03, -5.0491e-02],\n",
      "          [ 1.4349e-01,  1.4479e-01, -2.3132e-01],\n",
      "          [-6.9793e-02, -7.1843e-02, -6.9712e-02]],\n",
      "\n",
      "         [[-1.0094e-01,  1.5048e-01,  7.1275e-02],\n",
      "          [-2.6543e-01, -8.5824e-02, -2.8289e-01],\n",
      "          [-2.1090e-01, -3.4914e-01, -1.5224e-01]],\n",
      "\n",
      "         [[ 4.2640e-02, -6.7645e-02, -1.9036e-01],\n",
      "          [ 1.4812e-01,  1.8715e-01, -2.3859e-01],\n",
      "          [-1.1230e-01, -2.4701e-01,  9.5564e-02]]]], device='cuda:0')\n",
      "\n",
      "Layer: conv2.bias\n",
      "Shape: torch.Size([64])\n",
      "Weights: tensor([-0.0604, -0.0729, -0.0325, -0.0222, -0.0946, -0.0844, -0.0283, -0.0425,\n",
      "        -0.0820, -0.0055, -0.0440, -0.0356, -0.0527,  0.0129,  0.0058, -0.0025,\n",
      "        -0.0476, -0.0917, -0.1141, -0.0832, -0.0227, -0.0626, -0.0606, -0.0785,\n",
      "        -0.0803, -0.0183, -0.0028, -0.0835, -0.0898, -0.1004, -0.1185,  0.0116,\n",
      "        -0.0024,  0.0124, -0.1066, -0.0701, -0.1093, -0.0982, -0.1046, -0.0718,\n",
      "        -0.1173, -0.0360,  0.0049, -0.0726, -0.0698, -0.0708,  0.0003, -0.0970,\n",
      "        -0.0411, -0.1298, -0.0678, -0.0475, -0.0660,  0.0099, -0.1051, -0.0282,\n",
      "        -0.0733, -0.0461, -0.0758, -0.0699, -0.0295, -0.0289, -0.0033, -0.0133],\n",
      "       device='cuda:0')\n",
      "\n",
      "Layer: fc1.weight\n",
      "Shape: torch.Size([128, 3136])\n",
      "Weights: tensor([[-0.0151, -0.0020, -0.0021,  ...,  0.0056,  0.0045, -0.0150],\n",
      "        [ 0.0142,  0.0090, -0.0152,  ..., -0.0077,  0.0055, -0.0199],\n",
      "        [ 0.0089, -0.0049,  0.0143,  ..., -0.0014, -0.0448, -0.0475],\n",
      "        ...,\n",
      "        [-0.0160, -0.0154, -0.0092,  ..., -0.1383,  0.0327,  0.0263],\n",
      "        [-0.0167,  0.0101, -0.0031,  ...,  0.0064,  0.0252, -0.0199],\n",
      "        [ 0.0117, -0.0115, -0.0152,  ..., -0.0585, -0.0240, -0.0133]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Layer: fc1.bias\n",
      "Shape: torch.Size([128])\n",
      "Weights: tensor([-1.4733e-02, -6.2455e-03, -3.9521e-02, -7.1841e-02,  3.5599e-04,\n",
      "         1.2623e-02,  2.8503e-03, -6.3344e-02, -1.1712e-01, -2.3856e-02,\n",
      "        -5.2803e-02,  1.1204e-02, -5.3757e-02,  1.4123e-02, -1.1437e-02,\n",
      "        -3.3936e-02,  9.2058e-03, -6.5089e-03, -8.2884e-03,  1.5423e-03,\n",
      "        -3.1497e-03, -9.3382e-03, -4.2569e-02, -3.5373e-02, -3.3617e-02,\n",
      "        -4.1693e-02,  2.7922e-02, -1.0643e-02, -3.9691e-03, -2.3221e-02,\n",
      "        -2.0553e-02, -5.1079e-02, -4.1385e-02, -1.2931e-02, -2.4234e-02,\n",
      "        -2.6868e-02,  1.3578e-02, -2.2209e-02, -3.4107e-02,  2.0734e-02,\n",
      "        -7.0987e-02, -6.2364e-03,  1.7264e-02, -2.4381e-02, -2.1245e-02,\n",
      "        -2.0714e-02,  3.8638e-03,  2.6401e-03,  4.4704e-02, -1.4609e-02,\n",
      "         1.0329e-02, -5.5490e-03, -2.0661e-02, -1.4862e-05, -1.0744e-02,\n",
      "        -5.8903e-03,  4.9639e-02, -2.3335e-02, -6.3488e-03, -2.0499e-02,\n",
      "        -1.3720e-02, -1.0053e-05,  3.7355e-03, -7.8781e-03, -3.3293e-03,\n",
      "        -6.0610e-03, -2.3907e-02, -2.2519e-02, -4.8694e-02, -1.5030e-02,\n",
      "        -1.2900e-02, -9.0309e-02, -2.5803e-02, -2.1924e-02, -1.7927e-02,\n",
      "        -2.5261e-02,  5.4971e-03, -6.5405e-02, -9.8639e-03, -8.4812e-03,\n",
      "         8.8674e-03, -1.7606e-02,  1.4513e-04,  4.0916e-02, -1.7215e-02,\n",
      "        -1.7255e-02, -5.5104e-03, -1.5619e-02,  3.5341e-02,  2.0390e-03,\n",
      "        -6.0735e-02,  5.7022e-02,  4.6372e-02,  3.9915e-03, -5.4961e-03,\n",
      "         1.3711e-02, -4.8284e-02, -9.6702e-03, -3.1376e-02, -3.9451e-03,\n",
      "         4.3438e-03, -9.7304e-03, -2.1360e-05, -2.6702e-02,  1.4437e-02,\n",
      "         3.2959e-02,  3.4858e-02, -3.4774e-03, -2.6918e-02, -6.6300e-02,\n",
      "        -7.7313e-05, -1.7283e-02, -2.4684e-02, -2.0710e-02, -7.1954e-02,\n",
      "         9.9384e-03, -1.0525e-02, -4.6276e-03, -5.7400e-03,  2.4097e-03,\n",
      "        -7.4552e-03,  7.1197e-03, -1.0009e-02, -1.6400e-02, -9.3467e-02,\n",
      "        -4.2845e-02, -8.5239e-03, -3.1681e-02], device='cuda:0')\n",
      "\n",
      "Layer: fc2.weight\n",
      "Shape: torch.Size([10, 128])\n",
      "Weights: tensor([[-0.0499,  0.0302,  0.1296,  ...,  0.0668, -0.0632,  0.0885],\n",
      "        [-0.0609, -0.0002, -0.2416,  ..., -0.2161,  0.0635, -0.1592],\n",
      "        [ 0.0320, -0.0418, -0.1639,  ..., -0.0882, -0.0947, -0.0188],\n",
      "        ...,\n",
      "        [-0.0123,  0.0559, -0.2285,  ..., -0.2090, -0.1525, -0.1392],\n",
      "        [-0.0676,  0.0381,  0.1153,  ...,  0.0661, -0.0928, -0.1874],\n",
      "        [ 0.0526, -0.0926,  0.0978,  ..., -0.2254, -0.0576,  0.0957]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Layer: fc2.bias\n",
      "Shape: torch.Size([10])\n",
      "Weights: tensor([ 0.0732,  0.2403,  0.0374,  0.0583, -0.0501, -0.1104, -0.1382, -0.0705,\n",
      "         0.0208, -0.0857], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 获取每一层的参数\n",
    "for name, param in net.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}\")\n",
    "        print(f\"Shape: {param.data.shape}\")\n",
    "        print(f\"Weights: {param.data}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 使用gpu设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def predict_image(image_path, model, transform):\n",
    "    # 加载图片\n",
    "    image = Image.open(image_path).convert('L')  # 转换为灰度图像\n",
    "    image = transform(image).unsqueeze(0)  # 转换为 Tensor 并增加 batch 维度\n",
    "    image.to(device)\n",
    "\n",
    "    # 使用模型进行预测\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "    \n",
    "    return predicted.item()\n",
    "\n",
    "# 指定图片路径\n",
    "image_path = 'D:\\code\\python-learning\\mnist\\generic\\8.png'\n",
    "\n",
    "# 进行预测\n",
    "predicted_digit = predict_image(image_path, net, transform)\n",
    "print(f\"Predicted digit: {predicted_digit}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.10 ('python-learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "274deb4f93372eb5c9a207b9878bde76e734bb8a8f81ed86eb03424633135391"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
